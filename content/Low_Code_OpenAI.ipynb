{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ix5_fEMNMnm"
      },
      "source": [
        "# Step 1: To config your Azure OpenAI connection\n",
        "Please **change** this part according to your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "grSOYS3uNMnk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "API_KEY = '5b8ff8db18904a8987511f3641234567890' # The API key is fake here for your reference\n",
        "API_VERSION = \"2023-07-01-preview\"\n",
        "AZURE_ENDPOINT = \"https://uksouth-esg.openai.azure.com\"\n",
        "MODEL_NAME=\"gpt-35-turbo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEChYEVRNMni"
      },
      "source": [
        "# Step 2: To install the underlying packages\n",
        "Do not change this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Do NOT modify this file unless you are very familar with the packages and version dependecies!\n",
        "\n",
        "import micropip\n",
        "await micropip.install('https://dao.gpt/multidict-4.7.6-py3-none-any.whl', keep_going=True)\n",
        "await micropip.install('https://dao.gpt/frozenlist-1.4.0-py3-none-any.whl', keep_going=True)\n",
        "await micropip.install('https://dao.gpt/multidict-4.7.6-py3-none-any.whl', keep_going=True)\n",
        "await micropip.install('https://dao.gpt/frozenlist-1.4.0-py3-none-any.whl', keep_going=True)\n",
        "await micropip.install('https://dao.gpt/urllib3-2.1.0-py3-none-any.whl', keep_going=True)\n",
        "await micropip.install('https://dao.gpt/aiohttp-3.9.1-py3-none-any.whl', keep_going=True)\n",
        "await micropip.install('https://dao.gpt/openai-1.6.1-py3-none-any.whl', keep_going=True)\n",
        "await micropip.install(\"ssl\")\n",
        "import ssl\n",
        "await micropip.install(\"httpx\", keep_going=True)\n",
        "import httpx\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "import json\n",
        "import httpx\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "class URLLib3Transport(httpx.BaseTransport):\n",
        "    def __init__(self):\n",
        "        self.pool = urllib3.PoolManager()\n",
        "\n",
        "    def handle_request(self, request: httpx.Request):\n",
        "        payload = json.loads(request.content.decode(\"utf-8\").replace(\"'\",'\"'))\n",
        "        urllib3_response = self.pool.request(request.method, str(request.url), headers=request.headers, json=payload)\n",
        "        content = json.loads(urllib3_response.data.decode('utf-8'))\n",
        "        stream = httpx.ByteStream(json.dumps(content).encode(\"utf-8\"))\n",
        "        headers = [(b\"content-type\", b\"application/json\")]\n",
        "        return httpx.Response(200, headers=headers, stream=stream)\n",
        "httpx_client = httpx.Client(transport=URLLib3Transport())\n",
        "\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "azure_client = AzureOpenAI(\n",
        "  api_key = API_KEY,  \n",
        "  api_version = API_VERSION,\n",
        "  azure_endpoint = AZURE_ENDPOINT,\n",
        "  http_client=httpx_client # call the transport client here. This is very important !!!\n",
        "  # Please note the streaming mode is not supported yet. If you find a way to do so, please let us know.\n",
        ")\n",
        "# Utilitis for low coding AI\n",
        "\n",
        "your_messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
        "    ]\n",
        "\n",
        "def ask(question):\n",
        "    global your_messages\n",
        "    your_messages.append({\"role\": \"user\", \"content\": question})\n",
        "    response = azure_client.chat.completions.create(\n",
        "        model=MODEL_NAME, # model = \"deployment_name\".\n",
        "        messages=your_messages\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "    your_messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
        "\n",
        "def newtopic():\n",
        "    global your_messages\n",
        "    your_messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaXY3joFNMnn"
      },
      "source": [
        "# Step 3: To call OpenAI API as usual BUT with pre-created http_client\n",
        "azure_client ( AzureOpenAI ) has been pre-created!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI was founded by a group of technology entrepreneurs and researchers, including Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, John Schulman, and Wojciech Zaremba. These individuals came together with the goal of ensuring that artificial intelligence benefits all of humanity.\n"
          ]
        }
      ],
      "source": [
        "ask(\"Who were the founders of OpenAI?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As of my last knowledge update, OpenAI is headquartered in San Francisco, California, in the United States. The company's headquarters are located in the Silicon Valley area, which is known for being a hub of technology and innovation. However, please note that this information may have changed, so I recommend checking OpenAI's official website or contacting them directly for the most up-to-date information about their headquarters.\n"
          ]
        }
      ],
      "source": [
        "ask(\"Can you tell more about its headquarter?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "newtopic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatGPT, often referred to as GPT-3, is a state-of-the-art natural language processing model developed by OpenAI. It's part of the \"Generative Pre-trained Transformer\" (GPT) series of language models. ChatGPT is designed to understand and generate human-like text based on the input it receives. It can engage in conversations, answer questions, write essays, and perform a variety of other language-related tasks. ChatGPT has been trained on a diverse range of internet text and is capable of understanding and generating human-like responses across a wide array of topics.\n"
          ]
        }
      ],
      "source": [
        "ask(\"What is ChatGPT?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
